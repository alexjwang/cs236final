{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c76df6-6619-432e-9363-50ddfc8d4c3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install aitextgen\n",
    "#!pip install sentence_transformers\n",
    "#!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a671e3ce-6d55-4f57-bc39-ff7d7740b7b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive, copy_file_to_gdrive\n",
    "from aitextgen import aitextgen\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8631e137-3077-497c-a80e-599df6bcb257",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba56ede-1756-4eae-98d6-8ebbf3ffe6c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Clusters():\n",
    "    def __init__(self, n=10):\n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.num_clusters = n\n",
    "\n",
    "    def train(self, txt):\n",
    "        corpus_embeddings = self.embedder.encode(txt.values)\n",
    "        self.kmeans = KMeans(n_clusters=self.num_clusters,init='k-means++',max_iter=300,n_init=10,random_state=0)\n",
    "        self.kmeans.fit(corpus_embeddings)\n",
    "        return self.kmeans.predict(corpus_embeddings)\n",
    "\n",
    "\n",
    "    def test(self, txt):\n",
    "        corpus_embeddings = self.embedder.encode(txt.values)\n",
    "        return self.kmeans.predict(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f42d32b-e486-4236-a76e-b1fc7f72401a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and   \n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b41456-020f-43d8-aa19-dae970b2e4a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "train['text'] = \"Category: \" +  train.category + \" # \" + train.Rationale.str.replace('\"', '') + ' # ' + train.Problem\n",
    "train['prompt'] = \"Category: \" +  train.category + \" # \" + train.Rationale.str.replace('\"', '') + ' # '\n",
    "train['clean'] = train[['text']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "\n",
    "train.text.to_csv('rationale_train.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc93a49-01a6-4a13-9bbd-c1623923e518",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b4406-fcc2-4057-ba13-87a33a778442",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70d8eb2c-1545-407e-8dee-70e0c2e770a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"nreimers/MiniLM-L6-H384-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Didn't find file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/added_tokens.json. We won't load it.\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/vocab.txt\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/special_tokens_map.json\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "ncluster = 6\n",
    "physics = Clusters(ncluster)\n",
    "physics_train = physics.train(train[train.category == 'physics']['clean'])\n",
    "physics_test = physics.test(train[train.category == 'physics']['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "373007aa-1784-401b-9a1a-4c3ce00f5420",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "phys_expl = train[train.category == 'physics']\n",
    "phys_expl['cluster'] = physics_test\n",
    "phys_expl['prompt'] = \"Category: \" + phys_expl.category + \" # \" + phys_expl.Rationale.str.replace('\"', '') + \" # \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f5f225-1a43-46cd-a9a8-2ba877422f84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Rationale</th>\n",
       "      <th>options</th>\n",
       "      <th>correct</th>\n",
       "      <th>annotated_formula</th>\n",
       "      <th>linear_formula</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>clean</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6 workers should finish a job in 8 days . afte...</td>\n",
       "      <td>\"let rate of one worker be r = &gt; ( 6 * r ) * 8...</td>\n",
       "      <td>a ) 3 , b ) 4 , c ) 5 , d ) 6 , e ) 7</td>\n",
       "      <td>a</td>\n",
       "      <td>divide(subtract(multiply(6, 8), multiply(3, 6)...</td>\n",
       "      <td>add(n0,n3)|multiply(n0,n1)|multiply(n0,n2)|sub...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # let rate of one worker be ...</td>\n",
       "      <td>Category: physics # let rate of one worker be ...</td>\n",
       "      <td>category physics let rate one worker r 6 r 8 1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a train 125 m long passes a man , running at 1...</td>\n",
       "      <td>\"speed of the train relative to man = ( 125 / ...</td>\n",
       "      <td>a ) 60 , b ) 50 , c ) 28 , d ) 26 , e ) 29</td>\n",
       "      <td>a</td>\n",
       "      <td>divide(divide(subtract(125, multiply(multiply(...</td>\n",
       "      <td>multiply(n1,const_0_2778)|multiply(n1,#0)|subt...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # speed of the train relativ...</td>\n",
       "      <td>Category: physics # speed of the train relativ...</td>\n",
       "      <td>category physics speed train relative man 125 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kim finds a 5 - meter tree branch and marks it...</td>\n",
       "      <td>\"3 pieces of 1 / 5 length and two piece each o...</td>\n",
       "      <td>a ) 8 / 15 , b ) 1 / 2 , c ) 7 / 5 , d ) 3 / 5...</td>\n",
       "      <td>d</td>\n",
       "      <td>subtract(const_1, add(add(divide(5, multiply(a...</td>\n",
       "      <td>add(const_2,n0)|multiply(n0,#0)|divide(n0,#1)|...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # 3 pieces of 1 / 5 length a...</td>\n",
       "      <td>Category: physics # 3 pieces of 1 / 5 length a...</td>\n",
       "      <td>category physics 3 pieces 1 5 length two piece...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a garrison of 2000 men has provisions for 54 d...</td>\n",
       "      <td>\"2000 - - - - 54 2000 - - - - 39 x - - - - - 2...</td>\n",
       "      <td>a ) 1778 , b ) 1682 , c ) 9178 , d ) 1900 , e ...</td>\n",
       "      <td>d</td>\n",
       "      <td>subtract(divide(subtract(multiply(2000, 54), m...</td>\n",
       "      <td>multiply(n0,n1)|multiply(n0,n2)|subtract(#0,#1...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # 2000 - - - - 54 2000 - - -...</td>\n",
       "      <td>Category: physics # 2000 - - - - 54 2000 - - -...</td>\n",
       "      <td>category physics 2000 54 2000 39 x 20 x 20 200...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>how many seconds will a 900 meter long train m...</td>\n",
       "      <td>\"explanation : here distance d = 900 mts speed...</td>\n",
       "      <td>a ) 48 , b ) 36 , c ) 54 , d ) 11 , e ) 18</td>\n",
       "      <td>c</td>\n",
       "      <td>divide(900, multiply(subtract(63, 3), const_0_...</td>\n",
       "      <td>subtract(n1,n2)|multiply(#0,const_0_2778)|divi...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # explanation : here distanc...</td>\n",
       "      <td>Category: physics # explanation : here distanc...</td>\n",
       "      <td>category physics explanation distance 900 mts ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29825</th>\n",
       "      <td>find the area of trapezium whose parallel side...</td>\n",
       "      <td>\"area of a trapezium = 1 / 2 ( sum of parallel...</td>\n",
       "      <td>a ) 227 , b ) 299 , c ) 330 , d ) 161 , e ) 212</td>\n",
       "      <td>c</td>\n",
       "      <td>quadrilateral_area(15, 18, 26)</td>\n",
       "      <td>quadrilateral_area(n2,n1,n0)|</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # area of a trapezium = 1 / ...</td>\n",
       "      <td>Category: physics # area of a trapezium = 1 / ...</td>\n",
       "      <td>category physics area trapezium 1 2 sum parall...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29826</th>\n",
       "      <td>a train 160 m long passes a man , running at 6...</td>\n",
       "      <td>\"speed of train relative to man : 160 / 6 * 18...</td>\n",
       "      <td>a ) 54 kmph , b ) 60 kmph , c ) 66 kmph , d ) ...</td>\n",
       "      <td>e</td>\n",
       "      <td>divide(divide(subtract(160, multiply(multiply(...</td>\n",
       "      <td>multiply(n1,const_0_2778)|multiply(n1,#0)|subt...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # speed of train relative to...</td>\n",
       "      <td>Category: physics # speed of train relative to...</td>\n",
       "      <td>category physics speed train relative man 160 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29827</th>\n",
       "      <td>an aeroplane covers a certain distance at a sp...</td>\n",
       "      <td>\"distance = ( 240 x 6 ) = 1440 km . speed = di...</td>\n",
       "      <td>a ) 520 , b ) 620 , c ) 820 , d ) 740 , e ) 864</td>\n",
       "      <td>e</td>\n",
       "      <td>divide(divide(multiply(240, 6), add(const_1, d...</td>\n",
       "      <td>divide(const_2,const_3)|multiply(n0,n1)|add(#0...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # distance = ( 240 x 6 ) = 1...</td>\n",
       "      <td>Category: physics # distance = ( 240 x 6 ) = 1...</td>\n",
       "      <td>category physics distance 240 x 6 1440 km spee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29828</th>\n",
       "      <td>if 9 engines consume 24 metric tonnes of coal ...</td>\n",
       "      <td>let 3 engines of former type consume 1 unit in...</td>\n",
       "      <td>a ) 22 , b ) 24 , c ) 26 , d ) 28 , e ) none o...</td>\n",
       "      <td>c</td>\n",
       "      <td>multiply(13, multiply(divide(multiply(3, 24), ...</td>\n",
       "      <td>multiply(n1,n5)|multiply(n0,n2)|divide(#0,#1)|...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # let 3 engines of former ty...</td>\n",
       "      <td>Category: physics # let 3 engines of former ty...</td>\n",
       "      <td>category physics let 3 engines former type con...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29831</th>\n",
       "      <td>a man sitting in a train which is traveling at...</td>\n",
       "      <td>\"explanation : relative speed = 320 / 10 m / s...</td>\n",
       "      <td>a ) 52 kmph , b ) 56 kmph , c ) 60 kmph , d ) ...</td>\n",
       "      <td>c</td>\n",
       "      <td>subtract(multiply(divide(320, 10), const_3_6),...</td>\n",
       "      <td>divide(n2,n1)|multiply(#0,const_3_6)|subtract(...</td>\n",
       "      <td>physics</td>\n",
       "      <td>Category: physics # explanation : relative spe...</td>\n",
       "      <td>Category: physics # explanation : relative spe...</td>\n",
       "      <td>category physics explanation relative speed 32...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7063 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Problem  \\\n",
       "7      6 workers should finish a job in 8 days . afte...   \n",
       "11     a train 125 m long passes a man , running at 1...   \n",
       "20     kim finds a 5 - meter tree branch and marks it...   \n",
       "25     a garrison of 2000 men has provisions for 54 d...   \n",
       "28     how many seconds will a 900 meter long train m...   \n",
       "...                                                  ...   \n",
       "29825  find the area of trapezium whose parallel side...   \n",
       "29826  a train 160 m long passes a man , running at 6...   \n",
       "29827  an aeroplane covers a certain distance at a sp...   \n",
       "29828  if 9 engines consume 24 metric tonnes of coal ...   \n",
       "29831  a man sitting in a train which is traveling at...   \n",
       "\n",
       "                                               Rationale  \\\n",
       "7      \"let rate of one worker be r = > ( 6 * r ) * 8...   \n",
       "11     \"speed of the train relative to man = ( 125 / ...   \n",
       "20     \"3 pieces of 1 / 5 length and two piece each o...   \n",
       "25     \"2000 - - - - 54 2000 - - - - 39 x - - - - - 2...   \n",
       "28     \"explanation : here distance d = 900 mts speed...   \n",
       "...                                                  ...   \n",
       "29825  \"area of a trapezium = 1 / 2 ( sum of parallel...   \n",
       "29826  \"speed of train relative to man : 160 / 6 * 18...   \n",
       "29827  \"distance = ( 240 x 6 ) = 1440 km . speed = di...   \n",
       "29828  let 3 engines of former type consume 1 unit in...   \n",
       "29831  \"explanation : relative speed = 320 / 10 m / s...   \n",
       "\n",
       "                                                 options correct  \\\n",
       "7                  a ) 3 , b ) 4 , c ) 5 , d ) 6 , e ) 7       a   \n",
       "11            a ) 60 , b ) 50 , c ) 28 , d ) 26 , e ) 29       a   \n",
       "20     a ) 8 / 15 , b ) 1 / 2 , c ) 7 / 5 , d ) 3 / 5...       d   \n",
       "25     a ) 1778 , b ) 1682 , c ) 9178 , d ) 1900 , e ...       d   \n",
       "28            a ) 48 , b ) 36 , c ) 54 , d ) 11 , e ) 18       c   \n",
       "...                                                  ...     ...   \n",
       "29825    a ) 227 , b ) 299 , c ) 330 , d ) 161 , e ) 212       c   \n",
       "29826  a ) 54 kmph , b ) 60 kmph , c ) 66 kmph , d ) ...       e   \n",
       "29827    a ) 520 , b ) 620 , c ) 820 , d ) 740 , e ) 864       e   \n",
       "29828  a ) 22 , b ) 24 , c ) 26 , d ) 28 , e ) none o...       c   \n",
       "29831  a ) 52 kmph , b ) 56 kmph , c ) 60 kmph , d ) ...       c   \n",
       "\n",
       "                                       annotated_formula  \\\n",
       "7      divide(subtract(multiply(6, 8), multiply(3, 6)...   \n",
       "11     divide(divide(subtract(125, multiply(multiply(...   \n",
       "20     subtract(const_1, add(add(divide(5, multiply(a...   \n",
       "25     subtract(divide(subtract(multiply(2000, 54), m...   \n",
       "28     divide(900, multiply(subtract(63, 3), const_0_...   \n",
       "...                                                  ...   \n",
       "29825                     quadrilateral_area(15, 18, 26)   \n",
       "29826  divide(divide(subtract(160, multiply(multiply(...   \n",
       "29827  divide(divide(multiply(240, 6), add(const_1, d...   \n",
       "29828  multiply(13, multiply(divide(multiply(3, 24), ...   \n",
       "29831  subtract(multiply(divide(320, 10), const_3_6),...   \n",
       "\n",
       "                                          linear_formula category  \\\n",
       "7      add(n0,n3)|multiply(n0,n1)|multiply(n0,n2)|sub...  physics   \n",
       "11     multiply(n1,const_0_2778)|multiply(n1,#0)|subt...  physics   \n",
       "20     add(const_2,n0)|multiply(n0,#0)|divide(n0,#1)|...  physics   \n",
       "25     multiply(n0,n1)|multiply(n0,n2)|subtract(#0,#1...  physics   \n",
       "28     subtract(n1,n2)|multiply(#0,const_0_2778)|divi...  physics   \n",
       "...                                                  ...      ...   \n",
       "29825                      quadrilateral_area(n2,n1,n0)|  physics   \n",
       "29826  multiply(n1,const_0_2778)|multiply(n1,#0)|subt...  physics   \n",
       "29827  divide(const_2,const_3)|multiply(n0,n1)|add(#0...  physics   \n",
       "29828  multiply(n1,n5)|multiply(n0,n2)|divide(#0,#1)|...  physics   \n",
       "29831  divide(n2,n1)|multiply(#0,const_3_6)|subtract(...  physics   \n",
       "\n",
       "                                                    text  \\\n",
       "7      Category: physics # let rate of one worker be ...   \n",
       "11     Category: physics # speed of the train relativ...   \n",
       "20     Category: physics # 3 pieces of 1 / 5 length a...   \n",
       "25     Category: physics # 2000 - - - - 54 2000 - - -...   \n",
       "28     Category: physics # explanation : here distanc...   \n",
       "...                                                  ...   \n",
       "29825  Category: physics # area of a trapezium = 1 / ...   \n",
       "29826  Category: physics # speed of train relative to...   \n",
       "29827  Category: physics # distance = ( 240 x 6 ) = 1...   \n",
       "29828  Category: physics # let 3 engines of former ty...   \n",
       "29831  Category: physics # explanation : relative spe...   \n",
       "\n",
       "                                                  prompt  \\\n",
       "7      Category: physics # let rate of one worker be ...   \n",
       "11     Category: physics # speed of the train relativ...   \n",
       "20     Category: physics # 3 pieces of 1 / 5 length a...   \n",
       "25     Category: physics # 2000 - - - - 54 2000 - - -...   \n",
       "28     Category: physics # explanation : here distanc...   \n",
       "...                                                  ...   \n",
       "29825  Category: physics # area of a trapezium = 1 / ...   \n",
       "29826  Category: physics # speed of train relative to...   \n",
       "29827  Category: physics # distance = ( 240 x 6 ) = 1...   \n",
       "29828  Category: physics # let 3 engines of former ty...   \n",
       "29831  Category: physics # explanation : relative spe...   \n",
       "\n",
       "                                                   clean  cluster  \n",
       "7      category physics let rate one worker r 6 r 8 1...        2  \n",
       "11     category physics speed train relative man 125 ...        1  \n",
       "20     category physics 3 pieces 1 5 length two piece...        4  \n",
       "25     category physics 2000 54 2000 39 x 20 x 20 200...        2  \n",
       "28     category physics explanation distance 900 mts ...        1  \n",
       "...                                                  ...      ...  \n",
       "29825  category physics area trapezium 1 2 sum parall...        4  \n",
       "29826  category physics speed train relative man 160 ...        1  \n",
       "29827  category physics distance 240 x 6 1440 km spee...        0  \n",
       "29828  category physics let 3 engines former type con...        2  \n",
       "29831  category physics explanation relative speed 32...        1  \n",
       "\n",
       "[7063 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phys_expl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9e515-47a0-4a5d-8cc7-2b25d9ee89f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_expl['generated'] = phys_expl.apply(lambda row: ai_0.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_expl['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5466ecf-4de7-4f5a-baa6-22b44e998c86",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i in range(ncluster):\n",
    "  texts.append(' '.join(phys_expl[phys_expl.cluster == i].clean.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baec836-47ba-4c04-992c-6e873e181adb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ai = aitextgen()\n",
    "ai.train('rationale_train_0.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=3000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=False,\n",
    "         batch_size=1,\n",
    "         output_dir='trained_model_0'\n",
    "         )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddb11d-c6a6-4c6f-857e-c61297eb502b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ai = aitextgen()\n",
    "ai.train('rationale_train.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=3000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=False,\n",
    "         batch_size=1, \n",
    "         )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8231605-a784-44e5-8852-ef520e4df3a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ai_5 = aitextgen()\n",
    "ai_5.train('rationale_train_5.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=3000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=False,\n",
    "         batch_size=1,\n",
    "         output_dir='trained_model_5'\n",
    "         )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f6e9f-0db8-43eb-8ab3-badf3a852edc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ai_3 = aitextgen()\n",
    "ai_3.train('rationale_train_3.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=3000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=False,\n",
    "         batch_size=1,\n",
    "         output_dir='trained_model_3'\n",
    "         )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a6d4c-898a-40fe-a296-92141906fb69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ai_4 = aitextgen()\n",
    "ai_4.train('rationale_train_4.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=3000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=False,\n",
    "         batch_size=1,\n",
    "         output_dir='trained_model_4'\n",
    "         )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3b69b-045b-4ca3-999c-edf534d3b38b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_json('test.json')\n",
    "test['prompt'] = \"Category: \" + test.category + \" # \" + test.Rationale.str.replace('\"', '') + \" # \"\n",
    "test['text'] = \"Category: \" + test.category + \" # \" + test.Rationale.str.replace('\"', '') + \" # \" + test.Problem\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422907b-93d8-4b5c-b3a5-3f52eea47dea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test = test[test.category == 'physics']\n",
    "phys_test['clean'] = phys_test[['text']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "phys_test['cluster'] = physics.test(phys_test)\n",
    "phys_test_0 = phys_test[phys_test.cluster == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d0ad98-3df0-435f-8956-68da0e457ddb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ai = aitextgen(model_folder='trained_model', to_gpu=True)\n",
    "ai_0 = aitextgen(model_folder='trained_model_0', to_gpu=True)\n",
    "#ai_1 = aitextgen(model_folder='trained_model_1', to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b69a6-b616-42ef-97bc-84156ed8a778",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_0['generated'] = phys_test_0.apply(lambda row: ai_0.generate(n=5, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test_0['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6afeea9b-8112-40c9-aa6f-a6deccc87d63",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "class Comparer():\n",
    "    def __init__(self, l=1.0):\n",
    "        self.l = l\n",
    "        self.pattern = r'[0-9][0-9]*'\n",
    "\n",
    "    def convert(self, s):\n",
    "        nums = list(filter(lambda elem: elem.isnumeric(), s.split(' ')))\n",
    "        new_string = re.sub(self.pattern, 'Var', s)\n",
    "        return new_string, nums\n",
    "\n",
    "    def lossy_numbers(self, l1, l2):\n",
    "        loss = 0\n",
    "        for i in range(min(len(l1), len(l2))):\n",
    "            if l1[i] != l2[i]:\n",
    "                loss += 1\n",
    "        loss += max(len(l1), len(l2)) - min(len(l1), len(l2))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def loss_sentences(self, s1, s2):\n",
    "        m1, l1 = self.convert(s1)\n",
    "        m2, l2 = self.convert(s2)\n",
    "        return fuzz.partial_ratio(m1,m2)/100.0, self.l*(self.lossy_numbers(l1, l2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59612263-b428-4432-9811-3ea61e22f703",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = Comparer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292e6a2-1bd5-4310-87de-5b95c007a58a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phys_test_0['score'] = phys_test_0.apply(lambda row: c.loss_sentences(row['text'], row['generated'][0]), axis=1)\n",
    "phys_test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d3542-52ac-4bd9-a10e-c817f5f29c34",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phys_test_0['gpt_generated'] = phys_test_0.apply(lambda row: ai.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test_0['gpt_generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30940539-abd2-4736-8e13-fe0727f1f85c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "phys_test_0['gpt_score'] = phys_test_0.apply(lambda row: c.loss_sentences(row['text'], row['gpt_generated'][0]), axis=1)\n",
    "phys_test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a42ba-1735-400c-b28b-032e2e5ece9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phys_test_0.to_csv('output_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3fbf7-8fa6-4b27-b064-323750684529",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_0 = pd.read_csv('output_0.csv').iloc[:, 1:]\n",
    "phys_test_0['score'] = phys_test_0.apply(lambda row: eval(row['score']), axis=1)\n",
    "phys_test_0['gpt_score'] = phys_test_0.apply(lambda row: eval(row['gpt_score']), axis=1)\n",
    "phys_test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44e6fc-cec1-4d4e-b600-e16556e0c200",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phys_test_0[['s_score', 'n_score']] = phys_test_0.score.tolist()\n",
    "phys_test_0[['s_gptscore', 'n_gptscore']] = phys_test_0.gpt_score.tolist()\n",
    "print(phys_test_0.s_score.mean())\n",
    "print(phys_test_0.s_gptscore.mean())\n",
    "print(phys_test_0.n_score.mean())\n",
    "print(phys_test_0.n_gptscore.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e997d0a2-fcab-49ad-84f0-e8632c007fdb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_0.to_csv('output_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b1e0c-8674-42e0-bbdf-51088f639f92",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "phys_test['gpt_generated'] = phys_test.apply(lambda row: ai.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test['gpt_score'] = phys_test.apply(lambda row: c.loss_sentences(row['text'], row['gpt_generated'][0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7790cfb-bd7f-423c-b7ab-2f52b7f630b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test.to_csv('physicsgenerated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097e5fd-5cb6-4076-9397-3c9039cfbf9c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test = pd.read_csv('physicsgenerated.csv')\n",
    "phys_test['gpt_score'] = phys_test.apply(lambda row: eval(row['gpt_score']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76c30e-dc4a-4da2-bcf5-6bf0e4c97343",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test[['s_gptscore', 'n_gptscore']] = phys_test['gpt_score'].tolist()\n",
    "print(phys_test.s_gptscore.mean())\n",
    "print(phys_test.n_gptscore.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d9e80-1d27-4122-be1b-0505a579c5c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_1 = phys_test[phys_test.cluster == 1]\n",
    "phys_test_1['gpt_score'] = phys_test_1.apply(lambda row: c.loss_sentences(row['text'], row['gpt_generated'][0]), axis=1)\n",
    "phys_test[['s_gptscore', 'n_gptscore']] = phys_test['gpt_score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a67481-ad94-40d2-bf9c-d2c707472604",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_1['generated'] = phys_test_1.apply(lambda row: ai_1.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test_1['score'] = phys_test_1.apply(lambda row: c.loss_sentences(row['text'], row['generated'][0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9cf40-f1cf-4b80-ba47-7c9110b061ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_1[['s_score', 'n_score']] = phys_test_1.score.tolist()\n",
    "phys_test_1.to_csv('output_1.csv')\n",
    "print(phys_test_1.s_score.mean())\n",
    "print(phys_test_1.n_score.mean())\n",
    "print(phys_test[phys_test.cluster == 1].s_gptscore.mean())\n",
    "print(phys_test[phys_test.cluster == 1].n_gptscore.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ebe296-da57-45fc-aa5c-c4c88370f6d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ai_2 = aitextgen(model_folder='trained_model_2', to_gpu=True)\n",
    "ai_3 = aitextgen(model_folder='trained_model_3', to_gpu=True)\n",
    "ai_4 = aitextgen(model_folder='trained_model_4', to_gpu=True)\n",
    "ai_5 = aitextgen(model_folder='trained_model_5', to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc6abd-b7d4-4d4a-a34c-a4075437f829",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "phys_test_2 = phys_test[phys_test.cluster == 2]\n",
    "phys_test_2['generated'] = phys_test_2.apply(lambda row: ai_2.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test_2['score'] = phys_test_2.apply(lambda row: c.loss_sentences(row['text'], row['generated'][0]), axis=1)\n",
    "phys_test_2[['s_score', 'n_score']] = phys_test_2.score.tolist()\n",
    "phys_test_2.to_csv('output_2.csv')\n",
    "print(phys_test_2.s_score.mean())\n",
    "print(phys_test_2.n_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aaaf7d-3236-4523-bab5-2747c368a8af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_3 = phys_test[phys_test.cluster == 3]\n",
    "phys_test_3['generated'] = phys_test_3.apply(lambda row: ai_3.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test_3['score'] = phys_test_3.apply(lambda row: c.loss_sentences(row['text'], row['generated'][0]), axis=1)\n",
    "phys_test_3[['s_score', 'n_score']] = phys_test_3.score.tolist()\n",
    "phys_test_3.to_csv('output_3.csv')\n",
    "print(phys_test_3.s_score.mean())\n",
    "print(phys_test_3.n_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee052d-36bd-4347-9cff-f84416ed944f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_4 = phys_test[phys_test.cluster == 4]\n",
    "phys_test_4['generated'] = phys_test_4.apply(lambda row: ai_4.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test_4['score'] = phys_test_4.apply(lambda row: c.loss_sentences(row['text'], row['generated'][0]), axis=1)\n",
    "phys_test_4[['s_score', 'n_score']] = phys_test_4.score.tolist()\n",
    "phys_test_4.to_csv('output_4.csv')\n",
    "print(phys_test_4.s_score.mean())\n",
    "print(phys_test_4.n_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65ca81-9e48-4329-b254-3d53b79f8aac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phys_test_5 = phys_test[phys_test.cluster == 5]\n",
    "phys_test_5['generated'] = phys_test_5.apply(lambda row: ai_5.generate(n=1, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "phys_test_5['score'] = phys_test_5.apply(lambda row: c.loss_sentences(row['text'], row['generated'][0]), axis=1)\n",
    "phys_test_5[['s_score', 'n_score']] = phys_test_5.score.tolist()\n",
    "phys_test_5.to_csv('output_5.csv')\n",
    "print(phys_test_5.s_score.mean())\n",
    "print(phys_test_5.n_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113e34a-8712-47e9-a7e9-33ce8490f2d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(phys_test_0.s_score.mean() + phys_test_1.s_score.mean() + phys_test_2.s_score.mean() + phys_test_3.s_score.mean() + \\\n",
    " phys_test_4.s_score.mean() + phys_test_5.s_score.mean()) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bdb8c-ee8f-436e-a7b3-f401b3aa73a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(phys_test_0.n_score.mean() + phys_test_1.n_score.mean() + phys_test_2.n_score.mean() + phys_test_3.n_score.mean() + \\\n",
    " phys_test_4.n_score.mean() + phys_test_5.n_score.mean()) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07c679dc-e19f-43b4-9ea0-0ec64e3b5e69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and   \n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n",
    "\n",
    "class Comparer():\n",
    "    def __init__(self, l=1.0):\n",
    "        self.l = l\n",
    "        self.pattern = r'[0-9][0-9]*'\n",
    "\n",
    "    def convert(self, s):\n",
    "        nums = list(filter(lambda elem: elem.isnumeric(), s.split(' ')))\n",
    "        new_string = re.sub(self.pattern, 'Var', s)\n",
    "        return new_string, nums\n",
    "\n",
    "    def lossy_numbers(self, l1, l2):\n",
    "        loss = 0\n",
    "        for i in range(min(len(l1), len(l2))):\n",
    "            if l1[i] != l2[i]:\n",
    "                loss += 1\n",
    "        loss += max(len(l1), len(l2)) - min(len(l1), len(l2))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def loss_sentences(self, s1, s2):\n",
    "        m1, l1 = self.convert(s1)\n",
    "        m2, l2 = self.convert(s2)\n",
    "        #print(fuzz.ratio(m1,m2))\n",
    "        return -fuzz.partial_ratio(m1,m2)/100.0 + self.l*(self.lossy_numbers(l1, l2))\n",
    "    \n",
    "    def loss_sentences_output(self, s1, s2):\n",
    "        m1, l1 = self.convert(s1)\n",
    "        m2, l2 = self.convert(s2)\n",
    "        return -fuzz.partial_ratio(m1,m2)/100.0, self.l*(self.lossy_numbers(l1, l2))\n",
    "\n",
    "def get_val(s):\n",
    "    return list(filter(lambda elem: elem.isnumeric(), s.split(' ')))\n",
    "\n",
    "def get_label(s, l):\n",
    "    return list(map(lambda elem: 2*int(elem in l)-1, s.split(' ')))\n",
    "\n",
    "def generate_numbers(data, c):\n",
    "    data['labels'] = data.apply(lambda r: c.loss_sentences(r['clean'], r['generated_clean']) , axis=1)\n",
    "    #data['labels'] = np.log(data['labels'])\n",
    "    data['labels'] = data['labels']/data['labels'].max()\n",
    "    return data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7448d0da-73a5-4e65-ae62-7b70e4d6f58c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output = pd.read_csv('physicsgenerated.csv')\n",
    "output_0 = pd.read_csv('output_0.csv')\n",
    "output_1 = pd.read_csv('output_1.csv')\n",
    "output_2 = pd.read_csv('output_2.csv')\n",
    "output_3 = pd.read_csv('output_3.csv')\n",
    "output_4 = pd.read_csv('output_4.csv')\n",
    "output_5 = pd.read_csv('output_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfe74ba2-063b-46f3-9f1a-18b92e819667",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 03:40:51.990419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.003317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.004082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 03:40:52.006635: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-07 03:40:52.007260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.007966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.008714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.421444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.422233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.422922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 03:40:52.423618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8209 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "# Build a model\n",
    "inputs = layers.Input(shape=(384,))\n",
    "layer1 = layers.Dense(128, activation='relu')(inputs)\n",
    "layer2 = layers.Dense(128)(layer1)\n",
    "layer3 = keras.layers.LeakyReLU(alpha=0.3)(layer2)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(layer3)\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "print('Model Built')\n",
    "# Define custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c3909e1-9696-418c-9998-1a3fa3992f88",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ['Category: physics # distance covered by a in...\n",
       "1      ['Category: physics # records last 90 min on e...\n",
       "2      ['Category: physics # explanation : | - - - - ...\n",
       "3      ['Category: physics # the ratio is 2 : 3 = gym...\n",
       "4      ['Category: physics # in 36 minutes, car x tra...\n",
       "                             ...                        \n",
       "175    [\"Category: physics # here, drawing a quick sk...\n",
       "176    ['Category: physics # the total distance d tra...\n",
       "177    [\"Category: physics # solution let us name the...\n",
       "178    [\"Category: physics # number of stops in an ho...\n",
       "179    ['Category: physics # 35 * 18 / 5 = 126 kmph a...\n",
       "Name: generated, Length: 180, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_0['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73c14c-1455-4f3b-b8d8-c7c6a12409b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0['generated_clean'] = output_0[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "output_0['generated_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c94f0-1636-4597-ba87-34ac81417745",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0['generated_clean'] = output_0[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output_0, Comparer())\n",
    "output_0.to_csv('output_0.csv')\n",
    "\n",
    "output_1['generated_clean'] = output_1[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output_1, Comparer())\n",
    "output_1.to_csv('output_1.csv')\n",
    "\n",
    "output_2['generated_clean'] = output_2[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output_2, Comparer())\n",
    "output_2.to_csv('output_2.csv')\n",
    "\n",
    "output_3['generated_clean'] = output_3[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output_3, Comparer())\n",
    "output_3.to_csv('output_3.csv')\n",
    "\n",
    "output_4['generated_clean'] = output_4[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output_4, Comparer())\n",
    "output_4['loss'] = labels\n",
    "output_4.to_csv('output_4.csv')\n",
    "\n",
    "output_5['generated_clean'] = output_5[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output_5, Comparer())\n",
    "output_5.to_csv('output_5.csv')\n",
    "\n",
    "output['generated_clean'] = output[['gpt_generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output, Comparer())\n",
    "output.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43d4f2-782f-4064-83c1-93238ad763e0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0['generated_clean'] = output_0[['generated']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "labels = generate_numbers(output_0, Comparer())\n",
    "output_0.to_csv('output_0.csv')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse', # Call the loss function with the selected layer\n",
    "              metrics=['accuracy'])\n",
    "print('Model  compiled')\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model.fit(embedder.encode(output_0['generated_clean'].values), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7caf446d-bb8a-4cd6-b6d6-1d09c203fa54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfd722be-8a10-4f0c-8209-5cd62ed973ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0 = pd.read_csv('output_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "586b1081-9b27-4f42-a28c-db99871880c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0['generated'] = output_0.apply(lambda row: ai_0.generate(n=5, prompt=row['prompt'], repetition_penalty=1.1, return_as_list=True, max_length=500), axis=1)\n",
    "output_0[['generated_0', 'generated_1', 'generated_2', 'generated_3', 'generated_4']] = \\\n",
    "    output_0['generated'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49a0d680-55a7-40b2-8aca-5f1496f5bba9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0['generated_clean_0'] = output_0[['generated_0']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "output_0['generated_clean_1'] = output_0[['generated_1']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "output_0['generated_clean_2'] = output_0[['generated_2']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "output_0['generated_clean_3'] = output_0[['generated_3']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))\n",
    "output_0['generated_clean_4'] = output_0[['generated_4']].applymap(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,lst_stopwords=nltk.corpus.stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40d08efa-0f3e-4c6d-baa0-d4a093d2bcfc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0.to_csv('output_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe8a1932-8ed5-405b-aebd-784437cc4f0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'category physic distance covered 30 min 1 km b cover extra 1 km 1 hour 48 minute 9 5 hr e relative speed b 1 9 5 5 9 speed b speed 5 9 6 5 9 655 answer b Ñ‚ drove town town b speed 30 km hr 30 minute speed reduced 1 km hr distance speed km hr town go town b'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_0['generated_clean_0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfd58402-e8e8-4625-8add-bb747229d7aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/added_tokens.json. We won't load it.\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/vocab.txt\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/special_tokens_map.json\n",
      "loading file /home/jupyter/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      category physic distance covered 30 min 1 km b...\n",
       "1      category physic record last 90 min 2 side reco...\n",
       "2      category physic explanation 20 60 50 20 r 60 5...\n",
       "3      category physic ratio 2 3 gym ride 10 3 2 15 m...\n",
       "4      category physic 36 minute car x travel 21 mile...\n",
       "                             ...                        \n",
       "175    category physic drawing quick sketch theaction...\n",
       "176    category physic total distance traveled john g...\n",
       "177    category physic solution let u name brother b ...\n",
       "178    category physic number stop hour 60 5 12 dista...\n",
       "179          category physic 35 18 5 126 kmph answer c Éµ\n",
       "Name: output, Length: 180, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('.')\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "min_score = 10000\n",
    "min_col = ''\n",
    "for col in ['generated_clean_0', 'generated_clean_1', 'generated_clean_2', 'generated_clean_3', 'generated_clean_4']:\n",
    "    col_name = col + '_score'\n",
    "    output_0[col_name] = model.predict(embedder.encode(output_0[col].values))\n",
    "cols = ['generated_clean_0_score', 'generated_clean_1_score', 'generated_clean_2_score', 'generated_clean_3_score', 'generated_clean_4_score']\n",
    "output_0['min_col'] = output_0[cols].idxmin(axis=1)\n",
    "output_0['min_col'] = output_0.apply(lambda x: x['min_col'].strip('_score'), axis=1)\n",
    "output_0['output'] = output_0.apply(lambda x: x[x['min_col']], axis=1)\n",
    "output_0['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7e13260-bc5d-4190-8262-237c493ffb60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_0.to_csv('output_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8c67e7a-3cd1-46ed-8717-e66da21b91f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c = Comparer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0852a967-79df-458c-bbbd-b42a5d4d2000",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5844999999999997\n",
      "4.461111111111111\n"
     ]
    }
   ],
   "source": [
    "output_0['score'] = output_0.apply(lambda row: c.loss_sentences_output(row['clean'], row['output']), axis=1)\n",
    "output_0[['s_score', 'n_score']] = output_0.score.tolist()\n",
    "output_0.to_csv('output_0.csv')\n",
    "print(output_0.s_score.mean())\n",
    "print(output_0.n_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78b21e3c-7e8e-453d-8333-218e19e9380a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83, 2.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"a rectangular floor that measures 15 meters by 18 meters is to be covered with carpet squares that each measure 10 meters by 3 meters. if the carpet squares cost $ 12 apiece, how much will the carpet squares cost?\"\n",
    "s2 = \"a rectangular floor that measures 15 meters by 18 meters is to be covered with carpet squares that each measure 3 meters by 3 meters . if the carpet squares cost $12 apiece , what is the total cost for the number of carpet squares needed to cover the floor ?\"\n",
    "c.loss_sentences(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b2437-27c8-419d-9ce9-b31c4d31ad06",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
